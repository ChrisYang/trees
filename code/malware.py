# Standard library
import unittest
from collections import Counter

# External libraries
import numpy as np
import matplotlib.pyplot as plt


class Record:
    'The aim of this class is to hide the representation of labels and'
    'records from the random forest building and classification algorithm'

    def __init__(self, labels, features, names=None):
        'Initialize with labels and records'
        self.labels = labels
        self.features = features
        if names is None:
            self.names = np.arange(len(labels), dtype=int)
        else:
            self.names = names

        assert len(self.labels) == self.features.shape[0]
        self.fI = self.get_indicator_function()

    def size(self):
        'The number of records'
        return self.features.shape[0]

    def indexes(self):
        return self.names

    def label_distribution(self):
        'The count of labels'
        return Counter(self.labels)

    def H(self):
        'Computes the binary entropy of labelled data'
        v = np.array(self.label_distribution().values())
        d = np.array(v) / float(sum(v))
        return - sum(d * np.log(d))

    def get_random_feature(self):
        'Select a random feature and a random threshold'
        rec_num, f_num = self.features.shape
        fID = np.random.random_integers(0, f_num-1)
        record = np.random.random_integers(0, rec_num-1)
        value = self.features[record, fID]
        return (fID, value)

    def get_indicator_function(self):
        'Returns the function used to decide left or right on any feature'
        def fI(records, F):
            fID, value = F
            return (records[:, fID] <= value)
        return fI

    def split_on_feature(self, feature):
        'Split the records according to a feature'

        # Define the indicator
        indicator = self.fI(self.features, feature)
        
        ## Split into two recrod sets
        labelsLeft = self.labels[indicator]
        featuresLeft = self.features[indicator, :]
        namesLeft = None
        if self.names is not None:
            namesLeft = self.names[indicator]

        labelsRight = self.labels[~indicator]
        featuresRight = self.features[~indicator, :]
        namesRight = None
        if self.names is not None:
            namesRight = self.names[~indicator]

        L = Record(labelsLeft, featuresLeft, namesLeft)
        R = Record(labelsRight, featuresRight, namesRight)

        ## What is the info gain?
        HL, SL = L.H(), L.size()
        HR, SR = R.H(), R.size()
        Ha, Sa = self.H(), float(self.size())

        dH = Ha - HL * (SL/Sa) - HR * (SR/Sa)
        return dH, L, R

## --------------------------
## - The random forest code -
## --------------------------


def build_tree(records, levels=5, numfeatures=100, cutoff=0.001):
    'Train a decision tree based on labeled data and features'
    if levels == 0 or records.H() == 0.0:
        C1 = records.label_distribution()
        Leaf = (None, C1)
        return Leaf
    else:
        gain = 0.0
        data = None
        for _ in xrange(numfeatures):
            F = records.get_random_feature()
            dH, L, R = records.split_on_feature(F)

            if gain < dH and cutoff < dH:
                gain = dH
                data = (F, L, R)

        if data is None:
            return build_tree(records, levels=0)

        (F, L, R) = data

        M1 = build_tree(L, levels - 1, numfeatures)
        M2 = build_tree(R, levels - 1, numfeatures)
        Branch = (F, M1, M2)
        return Branch


class Forest:
    def __init__(self, trees=10, levels=5, numfeatures=100, cutoff=0.001):
        self.root = None

        self.trees = trees
        self.levels = levels
        self.numfeatures = numfeatures
        self.cutoff = cutoff

    def train(self, labels, features):
        self.root = []
        R = Record(labels, features)
        for t in xrange(self.trees):
            print "Built tree", t 
            T = build_tree(R, self.levels, self.numfeatures, self.cutoff)
            self.root += [T]

    def classify(self, features):
        recs, _ = features.shape
        result_shape = (features.shape[0], len(self.root))
        scores = np.zeros(result_shape)
        print scores.shape
        R = Record(np.arange(recs, dtype=int), features)

        for i, T in enumerate(self.root):
            for idxs, result in classify(T, R):
                for idx in idxs.indexes():
                    scores[idx, i] = float(result[0]) / sum(result.values())


        plt.cla()
        plt.clf()
        plt.close()

        plt.imshow(scores, cmap=plt.cm.gray)
        plt.title('Scores matrix')
        plt.savefig(r"../scratch/tree_scores.png", bbox_inches='tight')

        return scores


def classify(tree, records):
    'Get a decision for an item using a tree'
    if len(tree) == 2:
        assert tree[0] is None
        yield (records, tree[1])
    else:
        F, LT, RT = tree
        _, L, R = records.split_on_feature(F)

        ## Check we did not drop any records
        assert records.size() == (L.size() + R.size())

        if L.size() > 0:
            for x in classify(LT, L):
                yield x
        if R.size() > 0:
            for x in classify(RT, R):
                yield x

def ROC(scores, labels, names, name="STD"):
    P = len(labels[labels==1])
    N = len(labels[labels==0])

    ## Save raw results in a file:
    fr = file(r"../scratch/"+name+"_results.txt","w")
    for s, l, n in sorted(zip(scores,labels, names), key=lambda x: np.mean(x[0])):
        fr.write("%.4f\t%s\t%s\n" % (np.mean(s), int(l), n))
    fr.close()

    ## Make an ROC curve
    final_scores = np.mean(scores, axis=1)
    TP = []
    FP = []
    ACC = []
    for sc in sorted(final_scores):
        L = labels[final_scores <= sc]
        Pi = len(L[L==1])
        Ni = len(L[L==0])
        TP += [float(Pi) / P]
        FP += [float(Ni) / N]
        ACC += [(float(Pi) + (N - float(Ni)))/(P + N)]

    plt.cla()
    plt.clf()
    plt.close()
    
    acc_max = "%.2f" % max(ACC)

    plt.plot(FP, TP)
    plt.xlim((0,1))
    plt.ylim((0,1))
    plt.title('ROC Curve (accuracy=%s)' % acc_max)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.savefig(r"../scratch/"+name+"_ROC_curve.png", bbox_inches='tight')

    f = file(r"../scratch/"+name+"_ROC_curve.csv", "w")
    f.write("FalsePositive,TruePositive,Accuracy\n")
    for fp, tp, acc in zip(FP,TP, ACC):
        f.write("%s,%s,%s\n" % (fp, tp, acc))
    f.close()



## Read the csv files
def read_data(labelsname, distancename):
    ## Extract labels
    rawlabels = np.genfromtxt(labelsname, delimiter=',', dtype=None)
    labelmap = {}
    row_len = 0
    for row in rawlabels:
        row_len = max(row_len, len(row)-1)
        name = row[0]
        labelmap[name] = list(row)[1:]

    ## Extract distances
    rawdistances = np.genfromtxt(distancename, delimiter=',', dtype=None)
    names = rawdistances[0][1:]
    distances = np.array(rawdistances[1:, 1:], dtype=float)
    labels = np.zeros((len(names), row_len))
    
    for i, name in enumerate(names):
        labels[i, 0:(len(row))] = labelmap[name]

    del labelmap
    return distances, labels, names


def visualizedistances(data, figname=None):
    D, L, N = data
    sorted_indexes = np.argsort(L[:,0])

    D2 = D[sorted_indexes, :]
    D2 = D2[:, sorted_indexes]

    plt.cla()
    plt.clf()
    plt.close()

    plt.imshow(D2, cmap=plt.cm.gray)
    plt.title('Distance matrix')
    plt.savefig(figname, bbox_inches='tight')


def selectsubsets(data, features=200, training=400):
    D, L, N = data

    ## First identify the indexes of positives and negatives
    negatives = np.where(L[:,0] == 0)[0]
    positives = np.where(L[:,0] == 1)[0]

    np.random.shuffle(negatives)
    np.random.shuffle(positives)

    feature_set = np.hstack((negatives[:features], positives[:features]))
    training_set = np.hstack((negatives[features:training],
                        positives[features:training]))
    test_set = np.hstack((negatives[training:], positives[training:]))

    training_records = D[training_set, :]
    training_records = training_records[::, feature_set]
    training_records = np.hstack((training_records, L[training_set, 1:]))
    training_labels = L[training_set, 0]

    #training_labels = np.zeros(len(training_set), dtype=int)
    #training_labels[len(training_set)/2:] = np.ones(len(training_set)/2, dtype=int)

    print training_records.shape, training_labels.shape

    test_records = D[test_set, :]
    test_records = test_records[::, feature_set]
    test_records = np.hstack((test_records, L[test_set, 1:]))
    test_labels = L[test_set, 0]

    #test_labels = np.zeros(len(test_set), dtype=int)
    #test_labels[len(test_set)/2:] = np.ones(len(test_set)/2, dtype=int)

    training_data = (training_set, training_records, training_labels)
    test_data = (test_set, test_records, test_labels)

    return feature_set, training_data, test_data


class TestSeq(unittest.TestCase):

    def setUp(self):
        self.trees = 100

    def test_visualize(self):
        data = read_data('../data/filelabels.csv', '../data/ncdvals.csv')
        visualizedistances(data, '../scratch/distances.png')


    def test_malwareanalysis(self):
        data = read_data('../data/filelabels.csv', '../data/ncdvals.csv')

        D, L, N = data
        assert D.shape == (2000, 2000)
        assert len(L) == 2000
        assert len(L[0]) == 1
        assert len(N) == 2000

        feature_set, training_data, test_data = selectsubsets(data, features=100, training=400)
        (training_set, training_records, training_labels) = training_data
        (test_set, test_records, test_labels) = test_data

        R = Record(training_labels, training_records, training_set)
        T = build_tree(R)

        for (r, d) in classify(T, R):
            assert r.label_distribution() == d

        F = Forest(trees = self.trees, numfeatures = 30)
        F.train(training_labels, training_records)
        scores = F.classify(test_records)

        
        ROC(scores, test_labels, N[test_set], name="MATRIX_ONLY")

    def test_malwareanalysis_compress(self):
        data = read_data('../data/filelabels2.csv', '../data/ncdvals.csv')

        D, L, N = data
        assert D.shape == (2000, 2000)
        assert len(L) == 2000
        assert len(L[0]) == 2
        assert len(N) == 2000

        feature_set, training_data, test_data = selectsubsets(data, features=100, training=400)
        (training_set, training_records, training_labels) = training_data
        (test_set, test_records, test_labels) = test_data

        R = Record(training_labels, training_records, training_set)
        T = build_tree(R)

        for (r, d) in classify(T, R):
            assert r.label_distribution() == d

        F = Forest(trees = self.trees, numfeatures = 30)
        F.train(training_labels, training_records)
        scores = F.classify(test_records)

        
        ROC(scores, test_labels, N[test_set], name="MATRIX_COMPRESS")

    def test_compress_only(self):
        data = read_data('../data/filelabels2.csv', '../data/ncdvals.csv')

        D, L, N = data
        assert D.shape == (2000, 2000)
        assert len(L) == 2000
        assert len(L[0]) == 2
        assert len(N) == 2000

        feature_set, training_data, test_data = selectsubsets(data, features=0, training=400)
        (training_set, training_records, training_labels) = training_data
        (test_set, test_records, test_labels) = test_data

        R = Record(training_labels, training_records, training_set)
        T = build_tree(R)

        for (r, d) in classify(T, R):
            assert r.label_distribution() == d

        F = Forest(trees = self.trees, numfeatures = 30)
        F.train(training_labels, training_records)
        scores = F.classify(test_records)

        
        ROC(scores, test_labels, N[test_set], name="COMPRESS_ONLY")



if __name__ == '__main__':
    unittest.main()